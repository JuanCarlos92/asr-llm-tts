# ASR-LLM-TTS

ASR-LLM-TTS es un proyecto de automatizaciÃ³n con inteligencia artificial que procesa llamadas telefÃ³nicas en tiempo real. Utiliza **Python** con **FastAPI**, integra **Whisper** para transcripciÃ³n de voz, **GPT (LLM)** para generar respuestas y **TTS** para convertir texto en voz.

Este proyecto permite recibir llamadas vÃ­a **Twilio**, transcribir la voz del usuario, generar respuestas inteligentes y reproducirlas en tiempo real.

---

## ğŸ”¹ Funcionalidades

1. Recibe audio desde Twilio y lo acumula en un buffer.
2. Cuando hay suficiente audio, lo transcribe con Whisper.
3. EnvÃ­a el texto a GPT (LLM) y obtiene respuesta en lenguaje natural.
4. Convierte la respuesta en voz (TTS) y genera un archivo MP3/WAV.
5. Reproduce el audio al usuario en la llamada vÃ­a Twilio.
6. Soporte opcional para **streaming parcial de TTS** mientras llega la respuesta.

---

## âš™ï¸ TecnologÃ­as usadas

- **Python 3.11+**
- **FastAPI**: framework para el servidor y WebSocket
- **Twilio API**: para llamadas telefÃ³nicas y transmisiÃ³n de audio
- **OpenAI Whisper**: transcripciÃ³n de audio
- **OpenAI GPT-4o-mini**: generaciÃ³n de respuestas
- **OpenAI TTS**: conversiÃ³n de texto a voz
- **webrtcvad**: detecciÃ³n de voz activa (VAD)
- **dotenv**: gestiÃ³n de variables de entorno
- **ffmpeg**: conversiÃ³n de audio PCM â†’ WAV/MP3
- **ngrok** (opcional): exponer servidor local a Internet

---

## ğŸ“ Estructura del proyecto

```
asr-llm-tts/
â”œâ”€ main.py               # Servidor FastAPI, endpoints HTTP y WebSocket
â”œâ”€ session.py            # GestiÃ³n de sesiones de llamadas y procesamiento ASR â†’ LLM â†’ TTS
â”œâ”€ utils.py              # Funciones auxiliares: decodificaciÃ³n, transcripciÃ³n, GPT, TTS, Twilio
â”œâ”€ static/
â”‚  â””â”€ audio/             # Carpeta donde se guardan los audios generados
â”œâ”€ .env                  # Variables de entorno (no subir a GitHub)
â”œâ”€ .gitignore            # Ignora .env, audios generados y caches
â””â”€ README.md
```

---

## ğŸ›  InstalaciÃ³n

1. Clonar el repositorio:

```bash
git clone https://github.com/tu-usuario/asr-llm-tts.git
cd asr-llm-tts
```

2. Crear un entorno virtual:

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows
```

3. Instalar dependencias:

```bash
pip install -r requirements.txt
```

> Nota: `requirements.txt` debe incluir:
> ```
> fastapi
> uvicorn
> requests
> python-dotenv
> twilio
> webrtcvad
> ```

4. Instalar **ffmpeg** en tu sistema:

- **Linux**: `sudo apt install ffmpeg`
- **MacOS**: `brew install ffmpeg`
- **Windows**: [Descargar binarios](https://ffmpeg.org/download.html)

---

## âš™ï¸ ConfiguraciÃ³n (.env)

Crea un archivo `.env` en la raÃ­z del proyecto con las siguientes variables:

```env
# Twilio
TWILIO_ACCOUNT_SID=ACxxxxxxxxxxxxxxxxxxxxxxxxxxxx
TWILIO_AUTH_TOKEN=your_twilio_auth_token
TWILIO_NUMBER=+34xxxxxxxxx

# OpenAI
OPENAI_API_KEY=sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxx

# Host y rutas
NGROK_HOST=https://xxxx.ngrok.io    # opcional, solo desarrollo local
PUBLIC_HOST=https://tudominio.com   # dominio donde se expondrÃ¡n audios
MEDIA_WS_PATH=/media                # ruta para el WebSocket de Twilio

# Puerto del servidor
PORT=8000
```

> âš ï¸ Nunca subas tu `.env` a GitHub.

### `.gitignore` recomendado:

```
.env
/static/audio/*.mp3
/static/audio/*.wav
__pycache__/
*.pyc
*.pyo
logs/
tmp/
```

---

## ğŸš€ EjecuciÃ³n

Ejecuta el servidor con Uvicorn:

```bash
uvicorn main:app --host 0.0.0.0 --port 8000 --reload
```

- Para pruebas locales con Twilio, usa **ngrok** para exponer el puerto 8000:

```bash
ngrok http 8000
```

- Configura la URL de **Incoming Call** en Twilio con:

```
https://xxxx.ngrok.io/incoming
```

---

## ğŸ“¡ Flujo de la llamada

1. Usuario llama al nÃºmero de Twilio.
2. Twilio transmite el audio al endpoint `/media/{call_sid}`.
3. `session.py` acumula audio â†’ lo transcribe con Whisper.
4. Texto transcrito â†’ GPT â†’ respuesta de texto.
5. Respuesta â†’ TTS â†’ se reproduce en la llamada.
6. Repetir mientras dura la conversaciÃ³n.

---

## ğŸ” Buenas prÃ¡cticas

- **Variables sensibles** en `.env` â†’ nunca subir a GitHub.
- **Audios generados** no subir â†’ incluir en `.gitignore`.
- Revisar logs de errores para detectar problemas de TTS o LLM.

---

## ğŸ“Œ Notas

- El proyecto soporta **streaming de LLM** y TTS parcial.
- Compatible con **multisesiÃ³n** â†’ varias llamadas simultÃ¡neas.
- Ideal para bots de atenciÃ³n telefÃ³nica, asistentes automÃ¡ticos o pruebas de AI conversacional.

##Estado del proyecto:
El proyecto actualmente funciona, permitiendo recibir llamadas, transcribirlas y generar respuestas TTS, pero ##la integraciÃ³n completa con todas las APIs necesarias aÃºn estÃ¡ pendiente.

---

## âš¡ Licencia

MIT License Â© Juan Carlos Filter MartÃ­n
